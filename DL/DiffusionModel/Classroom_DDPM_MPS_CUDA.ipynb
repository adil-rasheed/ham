{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9c924b9",
   "metadata": {},
   "source": [
    "\n",
    "# Classroom DDPM (PyTorch) — CUDA / Apple Silicon (MPS) / CPU\n",
    "\n",
    "This notebook implements a **minimal, classroom-friendly DDPM** (Denoising Diffusion Probabilistic Model) that runs on **NVIDIA CUDA**, **Apple Silicon (MPS/Metal)**, or **CPU**.\n",
    "\n",
    "**What you’ll get:**\n",
    "- A tiny U-Net-based DDPM that trains on **CIFAR-10 (32×32, RGB)**\n",
    "- **Auto device** selection: MPS → CUDA → CPU\n",
    "- Clear, heavily commented cells you can teach from\n",
    "- Quick **training**, **sampling**, and **visualization** cells\n",
    "\n",
    "> Tip: On Macs with M1/M2/M3, PyTorch will automatically use the MPS backend if available.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ce738d",
   "metadata": {},
   "source": [
    "## 0) Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c72e41b",
   "metadata": {},
   "source": [
    "## 1) Reproducibility & Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "037e0273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, math, random\n",
    "from dataclasses import dataclass\n",
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, utils as vutils\n",
    "\n",
    "def seed_everything(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def get_device() -> torch.device:\n",
    "    # Prefer MPS (Apple Silicon), else CUDA, else CPU\n",
    "    if torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    return torch.device(\"cpu\")\n",
    "\n",
    "seed_everything(42)\n",
    "device = get_device()\n",
    "print(f\"Using device: {device}\")\n",
    "try:\n",
    "    torch.set_float32_matmul_precision(\"high\")\n",
    "except Exception as e:\n",
    "    print(\"Note:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f972c4",
   "metadata": {},
   "source": [
    "## 2) Diffusion Schedule Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef2307ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dataclass\n",
    "class DiffusionSchedule:\n",
    "    betas: torch.Tensor\n",
    "    alphas: torch.Tensor\n",
    "    alpha_cumprod: torch.Tensor\n",
    "    alpha_cumprod_prev: torch.Tensor\n",
    "    sqrt_alpha_cumprod: torch.Tensor\n",
    "    sqrt_one_minus_alpha_cumprod: torch.Tensor\n",
    "    sqrt_recip_alpha: torch.Tensor\n",
    "    posterior_variance: torch.Tensor\n",
    "\n",
    "def make_beta_schedule(T: int, beta_start: float = 1e-4, beta_end: float = 2e-2) -> torch.Tensor:\n",
    "    # Linear schedule from the original DDPM paper\n",
    "    return torch.linspace(beta_start, beta_end, T)\n",
    "\n",
    "def build_schedule(T: int) -> DiffusionSchedule:\n",
    "    betas = make_beta_schedule(T)\n",
    "    alphas = 1.0 - betas\n",
    "    alpha_cumprod = torch.cumprod(alphas, dim=0)\n",
    "    alpha_cumprod_prev = torch.cat([torch.tensor([1.0]), alpha_cumprod[:-1]])\n",
    "\n",
    "    sqrt_alpha_cumprod = torch.sqrt(alpha_cumprod)\n",
    "    sqrt_one_minus_alpha_cumprod = torch.sqrt(1.0 - alpha_cumprod)\n",
    "    sqrt_recip_alpha = torch.sqrt(1.0 / alphas)\n",
    "\n",
    "    # From Ho et al. (posterior variance)\n",
    "    posterior_variance = betas * (1.0 - alpha_cumprod_prev) / (1.0 - alpha_cumprod)\n",
    "\n",
    "    return DiffusionSchedule(\n",
    "        betas=betas,\n",
    "        alphas=alphas,\n",
    "        alpha_cumprod=alpha_cumprod,\n",
    "        alpha_cumprod_prev=alpha_cumprod_prev,\n",
    "        sqrt_alpha_cumprod=sqrt_alpha_cumprod,\n",
    "        sqrt_one_minus_alpha_cumprod=sqrt_one_minus_alpha_cumprod,\n",
    "        sqrt_recip_alpha=sqrt_recip_alpha,\n",
    "        posterior_variance=posterior_variance,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e394bfe",
   "metadata": {},
   "source": [
    "## 3) Time Embeddings (Sinusoidal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6928dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "\n",
    "class SinusoidalPositionEmbeddings(nn.Module):\n",
    "    def __init__(self, dim: int):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        half_dim = self.dim // 2\n",
    "        device = t.device\n",
    "        emb = math.log(10000) / (half_dim - 1)\n",
    "        emb = torch.exp(torch.arange(half_dim, device=device) * -emb)\n",
    "        emb = t.float().unsqueeze(1) * emb.unsqueeze(0)\n",
    "        emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=1)\n",
    "        if self.dim % 2 == 1:\n",
    "            emb = F.pad(emb, (0, 1))\n",
    "        return emb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e51176",
   "metadata": {},
   "source": [
    "## 4) Tiny U-Net (Classroom-Friendly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4761eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_ch: int, out_ch: int, time_dim: int, groups: int = 8):\n",
    "        super().__init__()\n",
    "        self.norm1 = nn.GroupNorm(groups, in_ch)\n",
    "        self.act1 = nn.SiLU()\n",
    "        self.conv1 = nn.Conv2d(in_ch, out_ch, 3, padding=1)\n",
    "\n",
    "        self.norm2 = nn.GroupNorm(groups, out_ch)\n",
    "        self.act2 = nn.SiLU()\n",
    "        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, padding=1)\n",
    "\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(time_dim, out_ch)\n",
    "        )\n",
    "\n",
    "        self.res_conv = nn.Conv2d(in_ch, out_ch, 1) if in_ch != out_ch else nn.Identity()\n",
    "\n",
    "    def forward(self, x: torch.Tensor, t_emb: torch.Tensor) -> torch.Tensor:\n",
    "        h = self.conv1(self.act1(self.norm1(x)))\n",
    "        t = self.time_mlp(t_emb).type_as(h)\n",
    "        h = h + t[:, :, None, None]\n",
    "        h = self.conv2(self.act2(self.norm2(h)))\n",
    "        return h + self.res_conv(x)\n",
    "\n",
    "class Down(nn.Module):\n",
    "    def __init__(self, in_ch: int, out_ch: int, time_dim: int):\n",
    "        super().__init__()\n",
    "        self.block1 = ResBlock(in_ch, out_ch, time_dim)\n",
    "        self.block2 = ResBlock(out_ch, out_ch, time_dim)\n",
    "        self.down = nn.Conv2d(out_ch, out_ch, 4, stride=2, padding=1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, t_emb: torch.Tensor):\n",
    "        x = self.block1(x, t_emb)\n",
    "        x = self.block2(x, t_emb)\n",
    "        skip = x\n",
    "        x = self.down(x)\n",
    "        return x, skip\n",
    "\n",
    "class Up(nn.Module):\n",
    "    def __init__(self, in_ch: int, out_ch: int, time_dim: int):\n",
    "        super().__init__()\n",
    "        self.up = nn.ConvTranspose2d(in_ch, out_ch, 4, stride=2, padding=1)\n",
    "        self.block1 = ResBlock(out_ch * 2, out_ch, time_dim)\n",
    "        self.block2 = ResBlock(out_ch, out_ch, time_dim)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, skip: torch.Tensor, t_emb: torch.Tensor):\n",
    "        x = self.up(x)\n",
    "        x = torch.cat([x, skip], dim=1)\n",
    "        x = self.block1(x, t_emb)\n",
    "        x = self.block2(x, t_emb)\n",
    "        return x\n",
    "\n",
    "class TinyUNet(nn.Module):\n",
    "    \"\"\"A very small U-Net that works for 32x32 images (CIFAR-10).\"\"\"\n",
    "    def __init__(self, base_ch: int = 64, time_dim: int = 256):\n",
    "        super().__init__()\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            SinusoidalPositionEmbeddings(time_dim),\n",
    "            nn.Linear(time_dim, time_dim * 4),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(time_dim * 4, time_dim)\n",
    "        )\n",
    "\n",
    "        self.in_conv = nn.Conv2d(3, base_ch, 3, padding=1)\n",
    "\n",
    "        # Down: 32 -> 16 -> 8\n",
    "        self.down1 = Down(base_ch, base_ch, time_dim)\n",
    "        self.down2 = Down(base_ch, base_ch * 2, time_dim)\n",
    "\n",
    "        # Bottleneck at 8x8\n",
    "        self.bot1 = ResBlock(base_ch * 2, base_ch * 4, time_dim)\n",
    "        self.bot2 = ResBlock(base_ch * 4, base_ch * 2, time_dim)\n",
    "\n",
    "        # Up: 8 -> 16 -> 32\n",
    "        self.up1 = Up(base_ch * 2, base_ch, time_dim)\n",
    "        self.up2 = Up(base_ch, base_ch, time_dim)\n",
    "\n",
    "        self.out_norm = nn.GroupNorm(8, base_ch)\n",
    "        self.out_act = nn.SiLU()\n",
    "        self.out_conv = nn.Conv2d(base_ch, 3, 3, padding=1)\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        def init(m):\n",
    "            if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.Linear)):\n",
    "                nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "        self.apply(init)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        t_emb = self.time_mlp(t)\n",
    "\n",
    "        x = self.in_conv(x)\n",
    "        x, s1 = self.down1(x, t_emb)\n",
    "        x, s2 = self.down2(x, t_emb)\n",
    "\n",
    "        x = self.bot1(x, t_emb)\n",
    "        x = self.bot2(x, t_emb)\n",
    "\n",
    "        x = self.up1(x, s2, t_emb)\n",
    "        x = self.up2(x, s1, t_emb)\n",
    "\n",
    "        x = self.out_conv(self.out_act(self.out_norm(x)))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c6bdd4",
   "metadata": {},
   "source": [
    "## 5) DDPM Core (Forward/Reverse Diffusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4539755",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DDPM(nn.Module):\n",
    "    def __init__(self, model: nn.Module, T: int = 1000):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.T = T\n",
    "        sched = build_schedule(T)\n",
    "        for k, v in sched.__dict__.items():\n",
    "            self.register_buffer(k, v)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def q_sample(self, x_start: torch.Tensor, t: torch.Tensor, noise: torch.Tensor = None) -> torch.Tensor:\n",
    "        if noise is None:\n",
    "            noise = torch.randn_like(x_start)\n",
    "        sqrt_ac = self.sqrt_alpha_cumprod[t].view(-1, 1, 1, 1)\n",
    "        sqrt_om = self.sqrt_one_minus_alpha_cumprod[t].view(-1, 1, 1, 1)\n",
    "        return sqrt_ac * x_start + sqrt_om * noise\n",
    "\n",
    "    def p_losses(self, x_start: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        noise = torch.randn_like(x_start)\n",
    "        x_noisy = self.q_sample(x_start, t, noise)\n",
    "        noise_pred = self.model(x_noisy, t)  # predict epsilon\n",
    "        return F.mse_loss(noise_pred, noise)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def p_sample(self, x: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        betas_t = self.betas[t].view(-1, 1, 1, 1)\n",
    "        sqrt_one_minus_ac_t = self.sqrt_one_minus_alpha_cumprod[t].view(-1, 1, 1, 1)\n",
    "        sqrt_recip_alpha_t = self.sqrt_recip_alpha[t].view(-1, 1, 1, 1)\n",
    "\n",
    "        eps_theta = self.model(x, t)\n",
    "        model_mean = sqrt_recip_alpha_t * (x - betas_t * eps_theta / sqrt_one_minus_ac_t)\n",
    "\n",
    "        if (t == 0).all():\n",
    "            return model_mean\n",
    "        else:\n",
    "            posterior_var = self.posterior_variance[t].view(-1, 1, 1, 1)\n",
    "            noise = torch.randn_like(x)\n",
    "            return model_mean + torch.sqrt(posterior_var) * noise\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(self, batch_size: int, device: torch.device, channels: int = 3, size: int = 32) -> torch.Tensor:\n",
    "        x = torch.randn(batch_size, channels, size, size, device=device)\n",
    "        for i in reversed(range(self.T)):\n",
    "            t = torch.full((batch_size,), i, device=device, dtype=torch.long)\n",
    "            x = self.p_sample(x, t)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb87c77",
   "metadata": {},
   "source": [
    "## 6) Data: CIFAR-10 Loader (Normalized to [-1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36cf32d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_cifar10_loader(data_root: str, batch_size: int, num_workers: int = 2) -> DataLoader:\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(32),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),  # map to [-1, 1]\n",
    "    ])\n",
    "    train_set = datasets.CIFAR10(root=data_root, train=True, download=True, transform=transform)\n",
    "    return DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd7b4f9",
   "metadata": {},
   "source": [
    "## 7) Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cf31de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_ddpm(epochs=2, batch_size=128, lr=2e-4, timesteps=1000, base_channels=64, time_dim=256, \n",
    "               data_root=\"data\", num_workers=2, run_dir=\"runs\", log_every=50, sample_every=1000, seed=42):\n",
    "    seed_everything(seed)\n",
    "    dev = get_device()\n",
    "    print(f\"Training on: {dev}\")\n",
    "    os.makedirs(run_dir, exist_ok=True)\n",
    "\n",
    "    model = TinyUNet(base_ch=base_channels, time_dim=time_dim).to(dev)\n",
    "    ddpm = DDPM(model, T=timesteps).to(dev)\n",
    "    loader = get_cifar10_loader(data_root, batch_size, num_workers)\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "\n",
    "    global_step = 0\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for x, _ in loader:\n",
    "            x = x.to(dev)\n",
    "            t = torch.randint(0, ddpm.T, (x.size(0),), device=dev).long()\n",
    "            loss = ddpm.p_losses(x, t)\n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            opt.step()\n",
    "\n",
    "            if global_step % log_every == 0:\n",
    "                print(f\"epoch {epoch+1}/{epochs} | step {global_step:06d} | loss {loss.item():.4f}\")\n",
    "\n",
    "            if global_step % sample_every == 0 and global_step > 0:\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    samples = ddpm.sample(batch_size=36, device=dev)\n",
    "                os.makedirs(run_dir, exist_ok=True)\n",
    "                grid_path = os.path.join(run_dir, f\"sample_step_{global_step}.png\")\n",
    "                grid = vutils.make_grid(samples, nrow=6, normalize=True, value_range=(-1, 1))\n",
    "                vutils.save_image(grid, grid_path)\n",
    "                print(f\"Saved {grid_path}\")\n",
    "                model.train()\n",
    "\n",
    "            global_step += 1\n",
    "\n",
    "        ckpt_path = os.path.join(run_dir, \"ddpm.pt\")\n",
    "        torch.save({\"model\": model.state_dict(), \"ddpm_T\": ddpm.T}, ckpt_path)\n",
    "        print(f\"Saved checkpoint to {ckpt_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04572be7",
   "metadata": {},
   "source": [
    "## 8) Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66ea6416",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@torch.no_grad()\n",
    "def sample_images(n_samples=36, outfile=\"samples/grid.png\", timesteps=1000, base_channels=64, time_dim=256, checkpoint=\"runs/ddpm.pt\"):\n",
    "    dev = get_device()\n",
    "    print(f\"Sampling on: {dev}\")\n",
    "    os.makedirs(os.path.dirname(outfile), exist_ok=True)\n",
    "\n",
    "    model = TinyUNet(base_ch=base_channels, time_dim=time_dim).to(dev)\n",
    "    T = timesteps\n",
    "    if os.path.isfile(checkpoint):\n",
    "        ckpt = torch.load(checkpoint, map_location=dev)\n",
    "        model.load_state_dict(ckpt[\"model\"])\n",
    "        T = ckpt.get(\"ddpm_T\", timesteps)\n",
    "        print(f\"Loaded checkpoint with T={T}\")\n",
    "    else:\n",
    "        print(\"No checkpoint found; sampling with randomly initialized model (results will be noise).\")\n",
    "\n",
    "    ddpm = DDPM(model, T=T).to(dev)\n",
    "    samples = ddpm.sample(batch_size=n_samples, device=dev, channels=3, size=32)\n",
    "    grid = vutils.make_grid(samples, nrow=int(n_samples**0.5), normalize=True, value_range=(-1, 1))\n",
    "    vutils.save_image(grid, outfile)\n",
    "    print(f\"Saved {outfile}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae72ca1",
   "metadata": {},
   "source": [
    "## 9) Visualize the Beta Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2f8e57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_beta_schedule(timesteps=1000, out=\"runs/beta_schedule.png\"):\n",
    "    os.makedirs(\"runs\", exist_ok=True)\n",
    "    sched = build_schedule(timesteps)\n",
    "    plt.figure()\n",
    "    plt.plot(sched.betas.cpu().numpy())\n",
    "    plt.title(\"Beta schedule (linear)\")\n",
    "    plt.xlabel(\"t\")\n",
    "    plt.ylabel(\"beta_t\")\n",
    "    plt.savefig(out, bbox_inches=\"tight\")\n",
    "    print(f\"Saved {out}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3093f29",
   "metadata": {},
   "source": [
    "## 10) Quickstart: Train → Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4bd0860e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170M/170M [06:29<00:00, 437kB/s]  \n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected weight to be a vector of size equal to the number of channels in input, but got weight of shape [128] and input of shape [128, 192, 16, 16]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# TRAIN (recommended demo settings for a quick classroom run)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrain_ddpm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2e-4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m          \u001b[49m\u001b[43mdata_root\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mruns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 19\u001b[0m, in \u001b[0;36mtrain_ddpm\u001b[0;34m(epochs, batch_size, lr, timesteps, base_channels, time_dim, data_root, num_workers, run_dir, log_every, sample_every, seed)\u001b[0m\n\u001b[1;32m     17\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(dev)\n\u001b[1;32m     18\u001b[0m t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, ddpm\u001b[38;5;241m.\u001b[39mT, (x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m),), device\u001b[38;5;241m=\u001b[39mdev)\u001b[38;5;241m.\u001b[39mlong()\n\u001b[0;32m---> 19\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mddpm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp_losses\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m opt\u001b[38;5;241m.\u001b[39mzero_grad(set_to_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     22\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "Cell \u001b[0;32mIn[5], line 21\u001b[0m, in \u001b[0;36mDDPM.p_losses\u001b[0;34m(self, x_start, t)\u001b[0m\n\u001b[1;32m     19\u001b[0m noise \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn_like(x_start)\n\u001b[1;32m     20\u001b[0m x_noisy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_sample(x_start, t, noise)\n\u001b[0;32m---> 21\u001b[0m noise_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_noisy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# predict epsilon\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mmse_loss(noise_pred, noise)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ham/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ham/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[4], line 103\u001b[0m, in \u001b[0;36mTinyUNet.forward\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m    100\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbot1(x, t_emb)\n\u001b[1;32m    101\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbot2(x, t_emb)\n\u001b[0;32m--> 103\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mup1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_emb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mup2(x, s1, t_emb)\n\u001b[1;32m    106\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_conv(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_act(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_norm(x)))\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ham/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ham/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[4], line 50\u001b[0m, in \u001b[0;36mUp.forward\u001b[0;34m(self, x, skip, t_emb)\u001b[0m\n\u001b[1;32m     48\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mup(x)\n\u001b[1;32m     49\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([x, skip], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 50\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblock1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_emb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblock2(x, t_emb)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ham/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ham/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[4], line 20\u001b[0m, in \u001b[0;36mResBlock.forward\u001b[0;34m(self, x, t_emb)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor, t_emb: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m---> 20\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact1(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m     21\u001b[0m     t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_mlp(t_emb)\u001b[38;5;241m.\u001b[39mtype_as(h)\n\u001b[1;32m     22\u001b[0m     h \u001b[38;5;241m=\u001b[39m h \u001b[38;5;241m+\u001b[39m t[:, :, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ham/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ham/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ham/lib/python3.12/site-packages/torch/nn/modules/normalization.py:313\u001b[0m, in \u001b[0;36mGroupNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_groups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ham/lib/python3.12/site-packages/torch/nn/functional.py:2960\u001b[0m, in \u001b[0;36mgroup_norm\u001b[0;34m(input, num_groups, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2953\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   2954\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected at least 2 dimensions for input tensor but received \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2955\u001b[0m     )\n\u001b[1;32m   2956\u001b[0m _verify_batch_size(\n\u001b[1;32m   2957\u001b[0m     [\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m num_groups, num_groups]\n\u001b[1;32m   2958\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m2\u001b[39m:])\n\u001b[1;32m   2959\u001b[0m )\n\u001b[0;32m-> 2960\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2961\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_groups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[1;32m   2962\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected weight to be a vector of size equal to the number of channels in input, but got weight of shape [128] and input of shape [128, 192, 16, 16]"
     ]
    }
   ],
   "source": [
    "# TRAIN (recommended demo settings for a quick classroom run)\n",
    "train_ddpm(epochs=2, batch_size=128, lr=2e-4, timesteps=1000, base_channels=64, time_dim=256,\n",
    "          data_root=\"data\", num_workers=2, run_dir=\"runs\", log_every=50, sample_every=1000, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29df9d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# SAMPLE (after training). Will use runs/ddpm.pt by default\n",
    "# sample_images(n_samples=36, outfile=\"samples/grid.png\", timesteps=1000, base_channels=64, time_dim=256, checkpoint=\"runs/ddpm.pt\")\n",
    "\n",
    "print(\"Uncomment the line above to sample.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07915864",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# VIZ (optional): visualize beta schedule\n",
    "# visualize_beta_schedule(timesteps=1000, out=\"runs/beta_schedule.png\")\n",
    "\n",
    "print(\"Uncomment the line above to visualize the beta schedule.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad011e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.6.0\n",
      "MPS (Metal) device available: True\n",
      "MPS (Metal) device built: True\n",
      "Using MPS device\n",
      "\n",
      "Test tensor device: mps:0\n",
      "Matrix multiplication successful on device: mps:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check PyTorch MPS (Metal Performance Shaders) availability\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"MPS (Metal) device available:\", torch.backends.mps.is_available())\n",
    "print(\"MPS (Metal) device built:\", torch.backends.mps.is_built())\n",
    "\n",
    "# Set up device\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using MPS device\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU device\")\n",
    "\n",
    "# Test device with a simple operation\n",
    "x = torch.randn(5, 3).to(device)\n",
    "print(\"\\nTest tensor device:\", x.device)\n",
    "y = x @ x.t()\n",
    "print(\"Matrix multiplication successful on device:\", y.device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ham",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
